# ğŸ§¦ Projet Chaussettes.io â€“ Analyse de logs en temps rÃ©el

Ce projet consiste Ã  dÃ©velopper un systÃ¨me d'analyse de logs HTTP en temps rÃ©el pour l'entreprise fictive **Chaussettes.io**, Ã  l'aide de **Python**, **Apache Spark** et **Kafka**. Il est divisÃ© en trois Ã©tapes Ã©volutives : **version minimale**, **version complÃ¨te**, et **version finale**.

---

## ğŸ“ Structure du dÃ©pÃ´t

```
.
â”œâ”€â”€ minimal/                    # Version minimale
â”‚   â”œâ”€â”€ log_generator.py
â”‚   â””â”€â”€ spark_streaming_analyzer.py
â”‚
â”œâ”€â”€ complet/                    # Version complÃ¨te
â”‚   â”œâ”€â”€ log_generator.py
â”‚   â”œâ”€â”€ spark_streaming_analyzer.py
â”‚   â”œâ”€â”€ conf/
â”‚   â”‚   â””â”€â”€ spark-defaults.conf
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ finale/                     # (Ã€ venir) Version finale avec Kafka, seuils, alertes, etc.
â””â”€â”€ README.md                   # Ce fichier
```

---

## ğŸ§ª PrÃ©requis

- Python â‰¥ 3.8
- Java JDK â‰¥ 17
- Apache Spark (3.4.1 ou 4.0.0)
- PySpark (`pip install pyspark`)

---

## ğŸ§© Version 1 : minimale

### ğŸ¯ Objectif :
- GÃ©nÃ©rer 1 ligne de log HTTP Apache par seconde (alÃ©atoire).
- Lire ces logs via une socket avec Spark Streaming.
- Afficher les erreurs HTTP dÃ©tectÃ©es (codes â‰¥ 400).

### â–¶ï¸ Lancement :

Dans un terminal :
```bash
python minimal/minimal.py
```

Puis dans un autre :
```bash
python minimal/sparkStreaming.py
```

---

## ğŸ§© Version 2 : complÃ¨te

### ğŸ¯ Objectif :
- GÃ©nÃ©rateur de logs **configurable via argparse**
- ContrÃ´le du taux d'erreurs par utilisateurs et par URLs
- Configuration du **chiffrement et de l'authentification Spark** pour la production

### âš™ï¸ ParamÃ¨tres du gÃ©nÃ©rateur (`log_gen.py`)

| Argument | Description |
|----------|-------------|
| `--rate` | Nombre de logs gÃ©nÃ©rÃ©s par seconde |
| `--error-users` | % d'utilisateurs qui gÃ©nÃ¨rent des erreurs |
| `--error-rate` | % des requÃªtes erronÃ©es chez ces utilisateurs |
| `--error-urls` | % d'URLs susceptibles de gÃ©nÃ©rer des erreurs |
| `--host` | HÃ´te pour le socket (par dÃ©faut : `localhost`) |
| `--port` | Port d'Ã©coute (par dÃ©faut : `9999`) |

### â–¶ï¸ Exemple de lancement :

```bash
python complet/log_gen.py --rate 10 --error-users 30 --error-rate 60 --error-urls 50
```

### ğŸ§  Analyse Spark Streaming :

```bash
python complet/sparkStreamingComplet.py
```

### ğŸ” SÃ©curitÃ© â€“ Configuration Spark pour la production

Un fichier `spark-defaults.conf` est fourni dans `complet/conf/`. Il contient :

```properties
spark.authenticate true
spark.authenticate.secret chaussettesIo
spark.network.crypto.enabled true
spark.io.encryption.enabled true
```

âš ï¸ **Note** : cette configuration est prÃªte pour un dÃ©ploiement sÃ©curisÃ© en production. Elle n'est **pas activÃ©e en environnement local** mais peut Ãªtre intÃ©grÃ©e directement via `--properties-file` ou `.config()` dans Spark.

---

## ğŸ§© Version 3 : finale (Ã  venir)

### ğŸ¯ Objectif :
- Envoi des logs dans Kafka (`http-logs`)
- Analyse Spark Streaming lisant Kafka et publiant des alertes dans `alerts`
- DÃ©termination automatique des seuils via Spark batch
- DÃ©ploiement automatisÃ© (ex : `docker-compose`)
- Documentation pour l'extensibilitÃ© du systÃ¨me

---
